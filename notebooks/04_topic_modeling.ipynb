{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Task 2.2: Topic Modeling & Keyword Extraction\n",
    "\n",
    "---\n",
    "\n",
    "##  Objective\n",
    "Extract key themes and topics from the reviews to understand specific customer pain points and delights.\n",
    "\n",
    "**Techniques:**\n",
    "1. N-gram Analysis (Bigrams/Trigrams)\n",
    "2. Keyword Extraction\n",
    "\n",
    "**Output:** Insights on top themes per bank.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T19:41:31.368880Z",
     "iopub.status.busy": "2025-12-02T19:41:31.368880Z",
     "iopub.status.idle": "2025-12-02T19:41:35.721961Z",
     "shell.execute_reply": "2025-12-02T19:41:35.718530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1500 records.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from pathlib import Path\n",
    "\n",
    "INPUT_FILE = Path(\"../data/processed/sentiment_results.csv\")\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "print(f\"Loaded {len(df)} records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”‘ N-Gram Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T19:41:35.966346Z",
     "iopub.status.busy": "2025-12-02T19:41:35.966346Z",
     "iopub.status.idle": "2025-12-02T19:41:36.008799Z",
     "shell.execute_reply": "2025-12-02T19:41:36.002355Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_ngrams(corpus, n=2, top_k=10):\n",
    "    vec = CountVectorizer(ngram_range=(n, n), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:top_k]\n",
    "\n",
    "def analyze_bank(bank_name):\n",
    "    print(f\"\\n=== {bank_name} Analysis ===\")\n",
    "    subset = df[df['bank_name'] == bank_name]\n",
    "    \n",
    "    # Cleaned text corpus\n",
    "    corpus = subset['cleaned_text'].dropna().astype(str).tolist()\n",
    "    \n",
    "    # Bigrams\n",
    "    print(\"Top 5 Themes (Bigrams):\")\n",
    "    for phrase, freq in get_top_ngrams(corpus, n=2, top_k=5):\n",
    "        print(f\"  - {phrase}: {freq}\")\n",
    "        \n",
    "    # Negative Bigrams (Pain Points)\n",
    "    neg_corpus = subset[subset['sentiment_label'] == 'Negative']['cleaned_text'].dropna().astype(str).tolist()\n",
    "    if neg_corpus:\n",
    "        print(\"Top 3 Pain Points (Negative Bigrams):\")\n",
    "        for phrase, freq in get_top_ngrams(neg_corpus, n=2, top_k=3):\n",
    "            print(f\"  - {phrase}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T19:41:36.024226Z",
     "iopub.status.busy": "2025-12-02T19:41:36.019684Z",
     "iopub.status.idle": "2025-12-02T19:41:36.516570Z",
     "shell.execute_reply": "2025-12-02T19:41:36.513908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CBE Analysis ===\n",
      "Top 5 Themes (Bigrams):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - doesn work: 30\n",
      "  - mobile banking: 29\n",
      "  - transaction history: 25\n",
      "  - using app: 24\n",
      "  - easy use: 22\n",
      "Top 3 Pain Points (Negative Bigrams):\n",
      "  - doesn work: 18\n",
      "  - mobile banking: 10\n",
      "  - error message: 9\n",
      "\n",
      "=== BOA Analysis ===\n",
      "Top 5 Themes (Bigrams):\n",
      "  - mobile banking: 49\n",
      "  - banking app: 35\n",
      "  - doesn work: 31\n",
      "  - developer options: 19\n",
      "  - worst app: 18\n",
      "Top 3 Pain Points (Negative Bigrams):\n",
      "  - mobile banking: 22\n",
      "  - banking app: 19\n",
      "  - worst app: 16\n",
      "\n",
      "=== Dashen Analysis ===\n",
      "Top 5 Themes (Bigrams):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - dashen bank: 73\n",
      "  - super app: 64\n",
      "  - easy use: 32\n",
      "  - dashen super: 29\n",
      "  - user friendly: 29\n",
      "Top 3 Pain Points (Negative Bigrams):\n",
      "  - worst app: 8\n",
      "  - banking app: 6\n",
      "  - worst banking: 4\n"
     ]
    }
   ],
   "source": [
    "for bank in df['bank_name'].unique():\n",
    "    analyze_bank(bank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
